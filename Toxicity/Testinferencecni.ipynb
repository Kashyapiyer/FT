{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "vapHOHT3rSOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "87D_uNSumeA0"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = '/content/drive/MyDrive/debertatftmdl'\n",
        "test_cases = [\n",
        "      \"beautiful movie.\",\n",
        "      \"This is a beautiful movie\",\n",
        "      \"This is such a hateful and horrible movie\",\n",
        "      \"You are an asshole\",\n",
        "      \"wonderful person\",\n",
        "      \"You are a wonderful person!\",\n",
        "      \"I hate you and wish you would die\",\n",
        "      \"The weather is nice today\",\n",
        "      \"You're completely stupid and useless\",\n",
        "      \"You idiot you will pay for this\",\n",
        "      \"You are rotten bloody person\",\n",
        "      \"You should be ashamed of yourself\",\n",
        "      \"You should die or hang yourself why are your still living\"\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9rZTaMHokNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aObLrUrQrCcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haEwoi54rBEg",
        "outputId": "9a1fafbf-a843-45c6-a471-1ef9f112cb34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCkFh6DBrGdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import torch, torch.nn as nn\n",
        "import pandas as pd\n",
        "from transformers import  AutoConfig, AutoModel\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DebertaForSequenceClassification\n",
        "\n",
        "class ToxicityPredictor:\n",
        "    def __init__(self, model_path=OUTPUT_DIR):\n",
        "        print(model_path)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "        config = AutoConfig.from_pretrained(model_path)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_path, config=config, ignore_mismatched_sizes=True\n",
        "        )\n",
        "\n",
        "        # Move to the selected device\n",
        "        #self.model.to(self.device)\n",
        "\n",
        "\n",
        "        self.model.resize_token_embeddings(len(self.tokenizer)) #add this line\n",
        "\n",
        "\n",
        "        # Ensure model is in evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Store the original state\n",
        "        self.original_state = deepcopy(self.model.state_dict())\n",
        "\n",
        "    def predict(self, text, threshold=0.5):\n",
        "        # Ensure model is in eval mode before each prediction\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = self.tokenizer(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=128,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            #.to(self.device)\n",
        "\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "            #outputs = self.model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "            print(outputs[0])\n",
        "\n",
        "            print(\"### logits####\")\n",
        "            print(outputs.logits)\n",
        "            print(\"##################\")\n",
        "\n",
        "\n",
        "            probabilities = torch.softmax(outputs.logits, dim=1)\n",
        "            print(\"####### probabilities ######\")\n",
        "            print(probabilities)\n",
        "\n",
        "            toxic_prob = probabilities[0][1].item()\n",
        "            print(\"### toxic_prob ####\")\n",
        "            print(toxic_prob)\n",
        "\n",
        "            prediction = 'Toxic' if toxic_prob >= threshold else 'Non-toxic'\n",
        "\n",
        "            return {\n",
        "                'text': text,\n",
        "                'prediction': prediction,\n",
        "                'toxic_probability': f\"{toxic_prob:.3f}\",\n",
        "                'non_toxic_probability': f\"{1-toxic_prob:.3f}\",\n",
        "                'raw_probabilities': probabilities[0].cpu().numpy()\n",
        "            }\n",
        "\n",
        "    def reset_model(self):\n",
        "        \"\"\"Reset model to original state\"\"\"\n",
        "        self.model.load_state_dict(self.original_state)"
      ],
      "metadata": {
        "id": "YBYwtJCamgb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_consistency(model_path, test_cases):\n",
        "    predictor = ToxicityPredictor(model_path)\n",
        "    intialrundict = {'contextstr': [], 'ToxicProbability': [], 'predictionresult': []}\n",
        "    # First run\n",
        "    print(\"First run:\")\n",
        "    for text in test_cases:\n",
        "        t = predictor.predict(text)\n",
        "        intialrundict['contextstr'].append(text)\n",
        "        intialrundict['ToxicProbability'].append(t['toxic_probability'])\n",
        "        intialrundict['predictionresult'].append(t['prediction'])\n",
        "    intialresultdf = pd.DataFrame(intialrundict)\n",
        "    print(intialresultdf.head(15))\n",
        "\n",
        "    print(\"################################################\")\n",
        "\n",
        "    # Reset model\n",
        "    predictor.reset_model()\n",
        "\n",
        "    # Second run\n",
        "    print(\"\\nSecond run:\")\n",
        "    secndrundict = {'contextstr': [], 'ToxicProbability': [], 'predictionresult': []}\n",
        "    for text in test_cases:\n",
        "        test = predictor.predict(text)\n",
        "        secndrundict['contextstr'].append(text)\n",
        "        secndrundict['ToxicProbability'].append(test['toxic_probability'])\n",
        "        secndrundict['predictionresult'].append(test['prediction'])\n",
        "\n",
        "    secondresultdf = pd.DataFrame(secndrundict)\n",
        "    print(secondresultdf.head(15))"
      ],
      "metadata": {
        "id": "jFk6e0P_mnKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_consistency(model_path=OUTPUT_DIR, test_cases=test_cases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP2JfpOEmpUi",
        "outputId": "2c27bfd8-a0fd-42a2-99fd-06a72a1a4908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/debertatftmdl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/debertatftmdl and are newly initialized: ['classifier.bias', 'classifier.weight', 'deberta.embeddings.position_embeddings.weight', 'deberta.encoder.layer.0.attention.self.in_proj.weight', 'deberta.encoder.layer.0.attention.self.q_bias', 'deberta.encoder.layer.0.attention.self.v_bias', 'deberta.encoder.layer.1.attention.self.in_proj.weight', 'deberta.encoder.layer.1.attention.self.q_bias', 'deberta.encoder.layer.1.attention.self.v_bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.weight', 'deberta.encoder.layer.10.attention.output.dense.bias', 'deberta.encoder.layer.10.attention.output.dense.weight', 'deberta.encoder.layer.10.attention.self.in_proj.weight', 'deberta.encoder.layer.10.attention.self.q_bias', 'deberta.encoder.layer.10.attention.self.v_bias', 'deberta.encoder.layer.10.intermediate.dense.bias', 'deberta.encoder.layer.10.intermediate.dense.weight', 'deberta.encoder.layer.10.output.LayerNorm.bias', 'deberta.encoder.layer.10.output.LayerNorm.weight', 'deberta.encoder.layer.10.output.dense.bias', 'deberta.encoder.layer.10.output.dense.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.weight', 'deberta.encoder.layer.11.attention.output.dense.bias', 'deberta.encoder.layer.11.attention.output.dense.weight', 'deberta.encoder.layer.11.attention.self.in_proj.weight', 'deberta.encoder.layer.11.attention.self.q_bias', 'deberta.encoder.layer.11.attention.self.v_bias', 'deberta.encoder.layer.11.intermediate.dense.bias', 'deberta.encoder.layer.11.intermediate.dense.weight', 'deberta.encoder.layer.11.output.LayerNorm.bias', 'deberta.encoder.layer.11.output.LayerNorm.weight', 'deberta.encoder.layer.11.output.dense.bias', 'deberta.encoder.layer.11.output.dense.weight', 'deberta.encoder.layer.2.attention.self.in_proj.weight', 'deberta.encoder.layer.2.attention.self.q_bias', 'deberta.encoder.layer.2.attention.self.v_bias', 'deberta.encoder.layer.3.attention.self.in_proj.weight', 'deberta.encoder.layer.3.attention.self.q_bias', 'deberta.encoder.layer.3.attention.self.v_bias', 'deberta.encoder.layer.4.attention.self.in_proj.weight', 'deberta.encoder.layer.4.attention.self.q_bias', 'deberta.encoder.layer.4.attention.self.v_bias', 'deberta.encoder.layer.5.attention.self.in_proj.weight', 'deberta.encoder.layer.5.attention.self.q_bias', 'deberta.encoder.layer.5.attention.self.v_bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.weight', 'deberta.encoder.layer.6.attention.output.dense.bias', 'deberta.encoder.layer.6.attention.output.dense.weight', 'deberta.encoder.layer.6.attention.self.in_proj.weight', 'deberta.encoder.layer.6.attention.self.q_bias', 'deberta.encoder.layer.6.attention.self.v_bias', 'deberta.encoder.layer.6.intermediate.dense.bias', 'deberta.encoder.layer.6.intermediate.dense.weight', 'deberta.encoder.layer.6.output.LayerNorm.bias', 'deberta.encoder.layer.6.output.LayerNorm.weight', 'deberta.encoder.layer.6.output.dense.bias', 'deberta.encoder.layer.6.output.dense.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.weight', 'deberta.encoder.layer.7.attention.output.dense.bias', 'deberta.encoder.layer.7.attention.output.dense.weight', 'deberta.encoder.layer.7.attention.self.in_proj.weight', 'deberta.encoder.layer.7.attention.self.q_bias', 'deberta.encoder.layer.7.attention.self.v_bias', 'deberta.encoder.layer.7.intermediate.dense.bias', 'deberta.encoder.layer.7.intermediate.dense.weight', 'deberta.encoder.layer.7.output.LayerNorm.bias', 'deberta.encoder.layer.7.output.LayerNorm.weight', 'deberta.encoder.layer.7.output.dense.bias', 'deberta.encoder.layer.7.output.dense.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.output.dense.bias', 'deberta.encoder.layer.8.attention.output.dense.weight', 'deberta.encoder.layer.8.attention.self.in_proj.weight', 'deberta.encoder.layer.8.attention.self.q_bias', 'deberta.encoder.layer.8.attention.self.v_bias', 'deberta.encoder.layer.8.intermediate.dense.bias', 'deberta.encoder.layer.8.intermediate.dense.weight', 'deberta.encoder.layer.8.output.LayerNorm.bias', 'deberta.encoder.layer.8.output.LayerNorm.weight', 'deberta.encoder.layer.8.output.dense.bias', 'deberta.encoder.layer.8.output.dense.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.weight', 'deberta.encoder.layer.9.attention.output.dense.bias', 'deberta.encoder.layer.9.attention.output.dense.weight', 'deberta.encoder.layer.9.attention.self.in_proj.weight', 'deberta.encoder.layer.9.attention.self.q_bias', 'deberta.encoder.layer.9.attention.self.v_bias', 'deberta.encoder.layer.9.intermediate.dense.bias', 'deberta.encoder.layer.9.intermediate.dense.weight', 'deberta.encoder.layer.9.output.LayerNorm.bias', 'deberta.encoder.layer.9.output.LayerNorm.weight', 'deberta.encoder.layer.9.output.dense.bias', 'deberta.encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/debertatftmdl and are newly initialized because the shapes did not match:\n",
            "- deberta.embeddings.word_embeddings.weight: found shape torch.Size([128100, 768]) in the checkpoint and torch.Size([50265, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First run:\n",
            "                                           contextstr ToxicProbability  \\\n",
            "0                                    beautiful movie.            0.455   \n",
            "1                           This is a beautiful movie            0.458   \n",
            "2           This is such a hateful and horrible movie            0.468   \n",
            "3                                  You are an asshole            0.465   \n",
            "4                                    wonderful person            0.437   \n",
            "5                         You are a wonderful person!            0.447   \n",
            "6                   I hate you and wish you would die            0.448   \n",
            "7                           The weather is nice today            0.457   \n",
            "8                You're completely stupid and useless            0.447   \n",
            "9                     You idiot you will pay for this            0.460   \n",
            "10                       You are rotten bloody person            0.440   \n",
            "11                  You should be ashamed of yourself            0.452   \n",
            "12  You should die or hang yourself why are your s...            0.460   \n",
            "\n",
            "   predictionresult  \n",
            "0         Non-toxic  \n",
            "1         Non-toxic  \n",
            "2         Non-toxic  \n",
            "3         Non-toxic  \n",
            "4         Non-toxic  \n",
            "5         Non-toxic  \n",
            "6         Non-toxic  \n",
            "7         Non-toxic  \n",
            "8         Non-toxic  \n",
            "9         Non-toxic  \n",
            "10        Non-toxic  \n",
            "11        Non-toxic  \n",
            "12        Non-toxic  \n",
            "################################################\n",
            "\n",
            "Second run:\n",
            "                                           contextstr ToxicProbability  \\\n",
            "0                                    beautiful movie.            0.455   \n",
            "1                           This is a beautiful movie            0.458   \n",
            "2           This is such a hateful and horrible movie            0.468   \n",
            "3                                  You are an asshole            0.465   \n",
            "4                                    wonderful person            0.437   \n",
            "5                         You are a wonderful person!            0.447   \n",
            "6                   I hate you and wish you would die            0.448   \n",
            "7                           The weather is nice today            0.457   \n",
            "8                You're completely stupid and useless            0.447   \n",
            "9                     You idiot you will pay for this            0.460   \n",
            "10                       You are rotten bloody person            0.440   \n",
            "11                  You should be ashamed of yourself            0.452   \n",
            "12  You should die or hang yourself why are your s...            0.460   \n",
            "\n",
            "   predictionresult  \n",
            "0         Non-toxic  \n",
            "1         Non-toxic  \n",
            "2         Non-toxic  \n",
            "3         Non-toxic  \n",
            "4         Non-toxic  \n",
            "5         Non-toxic  \n",
            "6         Non-toxic  \n",
            "7         Non-toxic  \n",
            "8         Non-toxic  \n",
            "9         Non-toxic  \n",
            "10        Non-toxic  \n",
            "11        Non-toxic  \n",
            "12        Non-toxic  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_consistency(model_path=OUTPUT_DIR, test_cases=[\"You should die or hang yourself\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiiqHrm5spyy",
        "outputId": "0d115002-b54f-4942-adf5-8d0ec8bb90c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/debertatftmdl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/debertatftmdl and are newly initialized: ['classifier.bias', 'classifier.weight', 'deberta.embeddings.position_embeddings.weight', 'deberta.encoder.layer.0.attention.self.in_proj.weight', 'deberta.encoder.layer.0.attention.self.q_bias', 'deberta.encoder.layer.0.attention.self.v_bias', 'deberta.encoder.layer.1.attention.self.in_proj.weight', 'deberta.encoder.layer.1.attention.self.q_bias', 'deberta.encoder.layer.1.attention.self.v_bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.bias', 'deberta.encoder.layer.10.attention.output.LayerNorm.weight', 'deberta.encoder.layer.10.attention.output.dense.bias', 'deberta.encoder.layer.10.attention.output.dense.weight', 'deberta.encoder.layer.10.attention.self.in_proj.weight', 'deberta.encoder.layer.10.attention.self.q_bias', 'deberta.encoder.layer.10.attention.self.v_bias', 'deberta.encoder.layer.10.intermediate.dense.bias', 'deberta.encoder.layer.10.intermediate.dense.weight', 'deberta.encoder.layer.10.output.LayerNorm.bias', 'deberta.encoder.layer.10.output.LayerNorm.weight', 'deberta.encoder.layer.10.output.dense.bias', 'deberta.encoder.layer.10.output.dense.weight', 'deberta.encoder.layer.11.attention.output.LayerNorm.bias', 'deberta.encoder.layer.11.attention.output.LayerNorm.weight', 'deberta.encoder.layer.11.attention.output.dense.bias', 'deberta.encoder.layer.11.attention.output.dense.weight', 'deberta.encoder.layer.11.attention.self.in_proj.weight', 'deberta.encoder.layer.11.attention.self.q_bias', 'deberta.encoder.layer.11.attention.self.v_bias', 'deberta.encoder.layer.11.intermediate.dense.bias', 'deberta.encoder.layer.11.intermediate.dense.weight', 'deberta.encoder.layer.11.output.LayerNorm.bias', 'deberta.encoder.layer.11.output.LayerNorm.weight', 'deberta.encoder.layer.11.output.dense.bias', 'deberta.encoder.layer.11.output.dense.weight', 'deberta.encoder.layer.2.attention.self.in_proj.weight', 'deberta.encoder.layer.2.attention.self.q_bias', 'deberta.encoder.layer.2.attention.self.v_bias', 'deberta.encoder.layer.3.attention.self.in_proj.weight', 'deberta.encoder.layer.3.attention.self.q_bias', 'deberta.encoder.layer.3.attention.self.v_bias', 'deberta.encoder.layer.4.attention.self.in_proj.weight', 'deberta.encoder.layer.4.attention.self.q_bias', 'deberta.encoder.layer.4.attention.self.v_bias', 'deberta.encoder.layer.5.attention.self.in_proj.weight', 'deberta.encoder.layer.5.attention.self.q_bias', 'deberta.encoder.layer.5.attention.self.v_bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.bias', 'deberta.encoder.layer.6.attention.output.LayerNorm.weight', 'deberta.encoder.layer.6.attention.output.dense.bias', 'deberta.encoder.layer.6.attention.output.dense.weight', 'deberta.encoder.layer.6.attention.self.in_proj.weight', 'deberta.encoder.layer.6.attention.self.q_bias', 'deberta.encoder.layer.6.attention.self.v_bias', 'deberta.encoder.layer.6.intermediate.dense.bias', 'deberta.encoder.layer.6.intermediate.dense.weight', 'deberta.encoder.layer.6.output.LayerNorm.bias', 'deberta.encoder.layer.6.output.LayerNorm.weight', 'deberta.encoder.layer.6.output.dense.bias', 'deberta.encoder.layer.6.output.dense.weight', 'deberta.encoder.layer.7.attention.output.LayerNorm.bias', 'deberta.encoder.layer.7.attention.output.LayerNorm.weight', 'deberta.encoder.layer.7.attention.output.dense.bias', 'deberta.encoder.layer.7.attention.output.dense.weight', 'deberta.encoder.layer.7.attention.self.in_proj.weight', 'deberta.encoder.layer.7.attention.self.q_bias', 'deberta.encoder.layer.7.attention.self.v_bias', 'deberta.encoder.layer.7.intermediate.dense.bias', 'deberta.encoder.layer.7.intermediate.dense.weight', 'deberta.encoder.layer.7.output.LayerNorm.bias', 'deberta.encoder.layer.7.output.LayerNorm.weight', 'deberta.encoder.layer.7.output.dense.bias', 'deberta.encoder.layer.7.output.dense.weight', 'deberta.encoder.layer.8.attention.output.LayerNorm.bias', 'deberta.encoder.layer.8.attention.output.LayerNorm.weight', 'deberta.encoder.layer.8.attention.output.dense.bias', 'deberta.encoder.layer.8.attention.output.dense.weight', 'deberta.encoder.layer.8.attention.self.in_proj.weight', 'deberta.encoder.layer.8.attention.self.q_bias', 'deberta.encoder.layer.8.attention.self.v_bias', 'deberta.encoder.layer.8.intermediate.dense.bias', 'deberta.encoder.layer.8.intermediate.dense.weight', 'deberta.encoder.layer.8.output.LayerNorm.bias', 'deberta.encoder.layer.8.output.LayerNorm.weight', 'deberta.encoder.layer.8.output.dense.bias', 'deberta.encoder.layer.8.output.dense.weight', 'deberta.encoder.layer.9.attention.output.LayerNorm.bias', 'deberta.encoder.layer.9.attention.output.LayerNorm.weight', 'deberta.encoder.layer.9.attention.output.dense.bias', 'deberta.encoder.layer.9.attention.output.dense.weight', 'deberta.encoder.layer.9.attention.self.in_proj.weight', 'deberta.encoder.layer.9.attention.self.q_bias', 'deberta.encoder.layer.9.attention.self.v_bias', 'deberta.encoder.layer.9.intermediate.dense.bias', 'deberta.encoder.layer.9.intermediate.dense.weight', 'deberta.encoder.layer.9.output.LayerNorm.bias', 'deberta.encoder.layer.9.output.LayerNorm.weight', 'deberta.encoder.layer.9.output.dense.bias', 'deberta.encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/debertatftmdl and are newly initialized because the shapes did not match:\n",
            "- deberta.embeddings.word_embeddings.weight: found shape torch.Size([128100, 768]) in the checkpoint and torch.Size([50265, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First run:\n",
            "tensor([[-0.0389, -0.0259]])\n",
            "### logits####\n",
            "tensor([[-0.0389, -0.0259]])\n",
            "##################\n",
            "####### probabilities ######\n",
            "tensor([[0.4968, 0.5032]])\n",
            "### toxic_prob ####\n",
            "0.5032382607460022\n",
            "                        contextstr ToxicProbability predictionresult\n",
            "0  You should die or hang yourself            0.503            Toxic\n",
            "################################################\n",
            "\n",
            "Second run:\n",
            "tensor([[-0.0389, -0.0259]])\n",
            "### logits####\n",
            "tensor([[-0.0389, -0.0259]])\n",
            "##################\n",
            "####### probabilities ######\n",
            "tensor([[0.4968, 0.5032]])\n",
            "### toxic_prob ####\n",
            "0.5032382607460022\n",
            "                        contextstr ToxicProbability predictionresult\n",
            "0  You should die or hang yourself            0.503            Toxic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlist = [\n",
        "      \"beautiful movie.\",\n",
        "      \"This is a beautiful movie\",\n",
        "      \"This is such a hateful and horrible movie\",\n",
        "      \"You are an asshole\",\n",
        "      \"wonderful person\",\n",
        "      \"You are a wonderful person!\",\n",
        "      \"I hate you and wish you would die\",\n",
        "      \"The weather is nice today\",\n",
        "      \"You're completely stupid and useless\",\n",
        "      \"You idiot you will pay for this\",\n",
        "      \"You are rotten bloody person\",\n",
        "      \"You should be ashamed of yourself\",\n",
        "      \"You should die or hang yourself why are your still living\",\n",
        "      \"You are a scumbag why dont you die nasty fellow\",\n",
        "      \"You are a asshole\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "b_kz2F_7pbVk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings, os\n",
        "import torch\n",
        "from debertaclassifier import CustomDebertaClassifier\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def infer_toxiccnfvalidator(contextstr, mdlpath=OUTPUT_DIR):\n",
        "    try:\n",
        "        ft_model = CustomDebertaClassifier()\n",
        "        binpath = mdlpath + '/pytorch_model.bin'\n",
        "        if os.path.exists(binpath):\n",
        "            ft_model.load_state_dict(torch.load(binpath))\n",
        "            ft_model.eval()\n",
        "            tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR +'/')\n",
        "            result = {}\n",
        "            result['contextstr'] = contextstr\n",
        "            with torch.no_grad():\n",
        "                #Tokenize inputs\n",
        "                inputs = tokenizer(contextstr, return_tensors=\"pt\")\n",
        "                output = ft_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "                #print(output[0][0])\n",
        "\n",
        "                print(output[0][0][0], output[0][0][1])\n",
        "                cnf_intr = torch.abs(abs(output[0][0][1]) - abs(output[0][0][0]))\n",
        "                print(f\"Absolute difference: {cnf_intr.item():.4f}\")\n",
        "\n",
        "                # get the outputtensor\n",
        "                evallabel = output[0].argmax().item()\n",
        "                result['cnf_intr'] = f\"{cnf_intr.item():.4f}\"\n",
        "                result['evallabel'] = evallabel\n",
        "                if evallabel==1:\n",
        "                  result['prediction'] = 'toxic'\n",
        "                else:\n",
        "                  result['prediction'] = 'non-toxic'\n",
        "            return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return (f\"Encountered error while performing inference: {e}\")"
      ],
      "metadata": {
        "id": "kiGNZAYcopVv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_toxiccnfvalidator(contextstr=\"You are a asshole\", mdlpath=OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkwrmrZxqjg1",
        "outputId": "f1f5a481-fe2a-4c89-ccb6-e800df73af9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-5.1721) tensor(5.0374)\n",
            "Absolute difference: 0.1347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contextstr': 'You are a asshole',\n",
              " 'cnf_intr': '0.1347',\n",
              " 'evallabel': 1,\n",
              " 'prediction': 'toxic'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "resultdict = {'contextstr': [],'cnf_intr': [],'evallabel': [], 'predictionresult': []}\n",
        "\n",
        "for s in testlist:\n",
        "    t = infer_toxiccnfvalidator(contextstr=s)\n",
        "    resultdict['contextstr'].append(s)\n",
        "    resultdict['cnf_intr'].append(t['cnf_intr'])\n",
        "    resultdict['evallabel'].append(t['evallabel'])\n",
        "    resultdict['predictionresult'].append(t['prediction'])\n",
        "resultdf = pd.DataFrame(resultdict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifILZqjqpb_M",
        "outputId": "39aece19-97d4-451f-b993-90d5b75bbba5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.5843) tensor(-2.7499)\n",
            "Absolute difference: 0.1656\n",
            "tensor(3.3614) tensor(-3.4493)\n",
            "Absolute difference: 0.0879\n",
            "tensor(-4.8856) tensor(4.7549)\n",
            "Absolute difference: 0.1307\n",
            "tensor(-5.1726) tensor(5.0368)\n",
            "Absolute difference: 0.1358\n",
            "tensor(3.0788) tensor(-3.1365)\n",
            "Absolute difference: 0.0577\n",
            "tensor(2.9462) tensor(-2.9178)\n",
            "Absolute difference: 0.0284\n",
            "tensor(-4.5914) tensor(4.5007)\n",
            "Absolute difference: 0.0906\n",
            "tensor(4.2531) tensor(-4.5266)\n",
            "Absolute difference: 0.2735\n",
            "tensor(-5.1585) tensor(5.0246)\n",
            "Absolute difference: 0.1339\n",
            "tensor(-5.0664) tensor(4.9276)\n",
            "Absolute difference: 0.1388\n",
            "tensor(-5.1367) tensor(4.9869)\n",
            "Absolute difference: 0.1499\n",
            "tensor(-4.9174) tensor(4.7916)\n",
            "Absolute difference: 0.1259\n",
            "tensor(-4.9788) tensor(4.8555)\n",
            "Absolute difference: 0.1233\n",
            "tensor(-5.1555) tensor(5.0284)\n",
            "Absolute difference: 0.1271\n",
            "tensor(-5.1721) tensor(5.0374)\n",
            "Absolute difference: 0.1347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "iDHxB-XStjV-",
        "outputId": "72cf1a94-deb9-404a-80dc-bfb7ead081f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           contextstr cnf_intr  evallabel  \\\n",
              "0                                    beautiful movie.   0.1656          0   \n",
              "1                           This is a beautiful movie   0.0879          0   \n",
              "2           This is such a hateful and horrible movie   0.1307          1   \n",
              "3                                  You are an asshole   0.1358          1   \n",
              "4                                    wonderful person   0.0577          0   \n",
              "5                         You are a wonderful person!   0.0284          0   \n",
              "6                   I hate you and wish you would die   0.0906          1   \n",
              "7                           The weather is nice today   0.2735          0   \n",
              "8                You're completely stupid and useless   0.1339          1   \n",
              "9                     You idiot you will pay for this   0.1388          1   \n",
              "10                       You are rotten bloody person   0.1499          1   \n",
              "11                  You should be ashamed of yourself   0.1259          1   \n",
              "12  You should die or hang yourself why are your s...   0.1233          1   \n",
              "13    You are a scumbag why dont you die nasty fellow   0.1271          1   \n",
              "14                                  You are a asshole   0.1347          1   \n",
              "\n",
              "   predictionresult  \n",
              "0         non-toxic  \n",
              "1         non-toxic  \n",
              "2             toxic  \n",
              "3             toxic  \n",
              "4         non-toxic  \n",
              "5         non-toxic  \n",
              "6             toxic  \n",
              "7         non-toxic  \n",
              "8             toxic  \n",
              "9             toxic  \n",
              "10            toxic  \n",
              "11            toxic  \n",
              "12            toxic  \n",
              "13            toxic  \n",
              "14            toxic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1894c64a-2be2-463b-adf1-e68352cb5345\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contextstr</th>\n",
              "      <th>cnf_intr</th>\n",
              "      <th>evallabel</th>\n",
              "      <th>predictionresult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beautiful movie.</td>\n",
              "      <td>0.1656</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a beautiful movie</td>\n",
              "      <td>0.0879</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is such a hateful and horrible movie</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You are an asshole</td>\n",
              "      <td>0.1358</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wonderful person</td>\n",
              "      <td>0.0577</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>You are a wonderful person!</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I hate you and wish you would die</td>\n",
              "      <td>0.0906</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The weather is nice today</td>\n",
              "      <td>0.2735</td>\n",
              "      <td>0</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>You're completely stupid and useless</td>\n",
              "      <td>0.1339</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>You idiot you will pay for this</td>\n",
              "      <td>0.1388</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>You are rotten bloody person</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>You should be ashamed of yourself</td>\n",
              "      <td>0.1259</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>You should die or hang yourself why are your s...</td>\n",
              "      <td>0.1233</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>You are a scumbag why dont you die nasty fellow</td>\n",
              "      <td>0.1271</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>You are a asshole</td>\n",
              "      <td>0.1347</td>\n",
              "      <td>1</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1894c64a-2be2-463b-adf1-e68352cb5345')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1894c64a-2be2-463b-adf1-e68352cb5345 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1894c64a-2be2-463b-adf1-e68352cb5345');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e62eac5b-c0b0-446a-8bda-586d12033400\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e62eac5b-c0b0-446a-8bda-586d12033400')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e62eac5b-c0b0-446a-8bda-586d12033400 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7d224160-5a2f-4c04-843a-9556d3b7e780\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultdf')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d224160-5a2f-4c04-843a-9556d3b7e780 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('resultdf');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "resultdf",
              "summary": "{\n  \"name\": \"resultdf\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"contextstr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"You idiot you will pay for this\",\n          \"You should be ashamed of yourself\",\n          \"beautiful movie.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnf_intr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"0.1388\",\n          \"0.1259\",\n          \"0.1656\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evallabel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictionresult\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"toxic\",\n          \"non-toxic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}